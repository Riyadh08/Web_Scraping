{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f68682-17cb-4a6d-b504-ab1e2b92cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping book 1: The Hunger Games (The Hunger Games, #1) by Suzanne Collins\n",
      "Scraping book 2: Harry Potter and the Order of the Phoenix (Harry Potter, #5) by J.K. Rowling\n",
      "Scraping book 3: Pride and Prejudice by Jane Austen\n",
      "Scraping book 4: To Kill a Mockingbird by Harper Lee\n",
      "Scraping book 5: The Book Thief by Markus Zusak\n",
      "Scraping book 6: Twilight (The Twilight Saga, #1) by Stephenie Meyer\n",
      "Scraping book 7: Animal Farm by George Orwell\n",
      "Scraping book 8: J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings by J.R.R. Tolkien\n",
      "Scraping book 9: The Chronicles of Narnia (The Chronicles of Narnia, #1-7) by C.S. Lewis\n",
      "Scraping book 10: The Fault in Our Stars by John Green\n",
      "Scraping complete. Data saved to goodreads_books_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Function to fetch URLs of nested pages (book detail pages) from the parent page\n",
    "def fetch_books_urls_and_details(parent_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(parent_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the parent page: {parent_url}\")\n",
    "        return []\n",
    "    \n",
    "    # Parse the HTML content of the parent page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract titles and authors directly from the parent page\n",
    "    book_data = []\n",
    "    for book in soup.find_all('tr', itemtype='http://schema.org/Book'):\n",
    "        title_tag = book.find('a', class_='bookTitle')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else 'Unknown Title'\n",
    "        \n",
    "        author_tag = book.find('a', class_='authorName')\n",
    "        author = author_tag.get_text(strip=True) if author_tag else 'Unknown Author'\n",
    "        \n",
    "        # The link to the book detail page\n",
    "        book_url = 'https://www.goodreads.com' + title_tag['href'] if title_tag else None\n",
    "        \n",
    "        # Scrape genre from the book detail page\n",
    "        genre = scrape_genre_from_book_page(book_url) if book_url else 'Unknown Genre'\n",
    "        \n",
    "        book_data.append({\n",
    "            'title': title,\n",
    "            'author': author,\n",
    "            'genre': genre\n",
    "        })\n",
    "    \n",
    "    return book_data\n",
    "\n",
    "# Function to scrape the genre from the book's detail page\n",
    "def scrape_genre_from_book_page(book_url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(book_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve the book page: {book_url}\")\n",
    "        return 'Unknown Genre'\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Goodreads might list genres as part of a 'genres' section\n",
    "    genre_tag = soup.find('a', class_='actionLinkLite bookPageGenreLink')\n",
    "    genre = genre_tag.get_text(strip=True) if genre_tag else 'Unknown Genre'\n",
    "    \n",
    "    return genre\n",
    "\n",
    "# Main function to scrape data from parent and nested pages\n",
    "def scrape_data_from_goodreads_list(parent_url, num_books):\n",
    "    all_books = []\n",
    "    \n",
    "    # Step 1: Get the books and their details (including links to the book detail pages)\n",
    "    books_data = fetch_books_urls_and_details(parent_url)\n",
    "    \n",
    "    # Step 2: Process a limited number of books (up to num_books)\n",
    "    for idx, book_data in enumerate(books_data[:num_books]):\n",
    "        print(f\"Scraping book {idx + 1}: {book_data['title']} by {book_data['author']}\")\n",
    "        all_books.append(book_data)\n",
    "        \n",
    "        # Add a delay to avoid overwhelming the server\n",
    "        time.sleep(2)\n",
    "    \n",
    "    return all_books\n",
    "\n",
    "# Example parent URL (Best Books Ever list)\n",
    "parent_url = 'https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
    "\n",
    "# Scrape data for the first 10 books (you can adjust the number)\n",
    "scraped_data = scrape_data_from_goodreads_list(parent_url, 10)\n",
    "\n",
    "# Convert the scraped data to a pandas DataFrame and save it to a CSV file\n",
    "df = pd.DataFrame(scraped_data)\n",
    "df.to_csv('goodreads_books_data.csv', index=False)\n",
    "\n",
    "print(\"Scraping complete. Data saved to goodreads_books_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c797f61-5d5f-4ea6-ad1b-e8b136161be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
